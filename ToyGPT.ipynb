{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "# ——— Yardımcı fonksiyonlar ———\n",
        "\n",
        "def dot(u, v):\n",
        "    return sum(ui*vi for ui, vi in zip(u, v))\n",
        "\n",
        "def matmul(vec, mat):\n",
        "    # vec: length m, mat: m x n  → çıktı: length n\n",
        "    m = len(vec)\n",
        "    n = len(mat[0])\n",
        "    return [sum(vec[i] * mat[i][j] for i in range(m)) for j in range(n)]\n",
        "\n",
        "def transpose(mat):\n",
        "    return list(map(list, zip(*mat)))\n",
        "\n",
        "def softmax(x):\n",
        "    ex = [math.exp(xi) for xi in x]\n",
        "    s = sum(ex)\n",
        "    return [ei/s for ei in ex]\n",
        "\n",
        "def random_matrix(rows, cols, scale=0.1):\n",
        "    return [[(random.random()*2-1)*scale for _ in range(cols)] for _ in range(rows)]\n",
        "\n",
        "# ——— TinyGPT Sınıfı ———\n",
        "\n",
        "class TinyGPT:\n",
        "    def __init__(self, vocab_size, d_model=32, block_size=8):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model    = d_model\n",
        "        self.block_size = block_size\n",
        "\n",
        "        # 1) Token ve pozisyon gömmeleri\n",
        "        self.token_emb = random_matrix(vocab_size, d_model)\n",
        "\n",
        "        print(self.token_emb)\n",
        "\n",
        "        self.pos_emb   = random_matrix(block_size, d_model)\n",
        "\n",
        "        print(self.pos_emb)\n",
        "\n",
        "        # 2) Self-attention parametreleri (QKV ve çıkış)\n",
        "        self.W_q = random_matrix(d_model, d_model)\n",
        "        self.W_k = random_matrix(d_model, d_model)\n",
        "        self.W_v = random_matrix(d_model, d_model)\n",
        "        self.W_o = random_matrix(d_model, d_model)\n",
        "\n",
        "        # 3) Son sınıflandırma katmanı\n",
        "        self.W_out = random_matrix(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        \"\"\"\n",
        "        idx: liste halinde token id’leri (uzunluk ≤ block_size)\n",
        "        döndürür: logits → [ [logits_pose0], [logits_pose1], … ]\n",
        "        \"\"\"\n",
        "        T = len(idx)\n",
        "        # 1) Embedding + positional\n",
        "        X = [\n",
        "            [ self.token_emb[token][d] + self.pos_emb[pos][d]\n",
        "              for d in range(self.d_model) ]\n",
        "            for pos, token in enumerate(idx)\n",
        "        ]\n",
        "\n",
        "        # 2) Q, K, V hesapla\n",
        "        Q = [ matmul(x, self.W_q) for x in X ]\n",
        "        K = [ matmul(x, self.W_k) for x in X ]\n",
        "        V = [ matmul(x, self.W_v) for x in X ]\n",
        "\n",
        "        # 3) Skorları hesapla ve normalize et (scaled dot‑product)\n",
        "        scores = []\n",
        "        for i in range(T):\n",
        "            row = []\n",
        "            for j in range(T):\n",
        "                row.append( dot(Q[i], K[j]) / math.sqrt(self.d_model) )\n",
        "            scores.append( softmax(row) )  # her pozisyon için T uzunluğunda ağırlık\n",
        "\n",
        "        # 4) Context = Ağırlıklı V toplamı\n",
        "        C = []\n",
        "        for i in range(T):\n",
        "            # scores[i] • V\n",
        "            c_i = [0.0]*self.d_model\n",
        "            for j in range(T):\n",
        "                for d in range(self.d_model):\n",
        "                    c_i[d] += scores[i][j] * V[j][d]\n",
        "            C.append(c_i)\n",
        "\n",
        "        # 5) Attention çıkışını W_o ile geçir\n",
        "        A = [ matmul(c, self.W_o) for c in C ]\n",
        "\n",
        "        # 6) Son logits: her pozisyon için vocab boyutunda skor\n",
        "        logits = [ matmul(a, self.W_out) for a in A ]\n",
        "        return logits\n",
        "\n",
        "    def generate(self, start_token, length):\n",
        "        \"\"\"\n",
        "        Tek tek token örnekleyerek sequence üretir.\n",
        "        start_token: başlangıç token id’si\n",
        "        length: üretilecek toplam token sayısı\n",
        "        \"\"\"\n",
        "        out = [start_token]\n",
        "        for _ in range(length-1):\n",
        "            # bağlamı son block_size kadar kes\n",
        "            context = out[-self.block_size:]\n",
        "            logits = self.forward(context)\n",
        "            # son pozisyonun logits’lerinden softmax ve sampling\n",
        "            probs = softmax(logits[-1])\n",
        "            # örnekleme\n",
        "            r = random.random()\n",
        "            cum = 0.0\n",
        "            for i,p in enumerate(probs):\n",
        "                cum += p\n",
        "                if r < cum:\n",
        "                    out.append(i)\n",
        "                    break\n",
        "        return out\n",
        "\n",
        "# ——— Örnek Kullanım ———\n",
        "\n",
        "# 1) Sözlük boyutu\n",
        "VOCAB_SIZE = 20    # toy örnek, gerçekte metindeki karakter sayısı\n",
        "\n",
        "# 2) Modeli başlat\n",
        "model = TinyGPT(vocab_size=VOCAB_SIZE, d_model=16, block_size=8)\n",
        "\n",
        "# 3) Rastgele bir input (ör. [1,5,3,7])\n",
        "inp = [random.randrange(VOCAB_SIZE) for _ in range(6)]\n",
        "print(\"input\",inp)\n",
        "logits = model.forward(inp)             # shape: 6 × VOCAB_SIZE\n",
        "print(\"Logits örneği:\", logits[0][:5], \"...\")\n",
        "\n",
        "# 4) Üretim\n",
        "start = random.randrange(VOCAB_SIZE)\n",
        "gen = model.generate(start_token=start, length=12)\n",
        "print(\"Üretilen token dizisi:\", gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfZbl8BlyGxR",
        "outputId": "a0664ec7-16a3-49a8-a85b-30be21ed9620"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.03451909282341033, 0.030536985587105804, 0.08726456679965298, 0.09249688034344102, 0.08156425193140565, -0.05849372420318662, 0.05427414317299861, 0.025817818723912114, 0.04736214560756007, 0.09956391247665829, -0.058381139169455226, 0.05008616205425303, -0.0916057227564427, -0.04221981581032779, 0.005854011774633872, -0.09257882295971294], [-0.0541540093569266, 0.026851421229987807, -0.08248777771749541, -0.08131775401732787, -0.02339116372909831, -0.027529689656032287, -0.040973500619457925, -0.040768436883314975, 0.08523910550213354, 0.0647606463773958, 0.05189481536352902, 0.004300298459824581, 0.07597801699438805, -0.08636610653877196, 0.0033527021199493802, -0.022243434751109927], [0.024154943010205644, 0.000638620436264148, 0.019655446853497894, 0.06668664756002306, -0.03853885659935004, -0.06630464581102316, -0.07481830483038657, -0.054532532551124, -0.005309621659375674, -0.03111181701372321, -0.004344538000112075, 0.07419897125994045, -0.012597900373247262, 0.053949567426283124, 0.05132821183363423, 0.018663509076539932], [-0.016125929144880626, 0.07991008693979046, 0.09846944141716206, 0.02961728374186752, -0.009540528807582806, -0.050839656892784274, -0.07556265970045478, -0.07725037638329753, 0.0033037617608087325, -0.06191773485024941, -0.014805329033728843, 0.004553522047168812, 0.03612034521525966, -0.05002099594281029, -0.01768335486951067, -0.07658928282523694], [0.06538282182906303, -0.010384748610528294, -0.048959261365685874, 0.04131608904136957, 0.035844810900203465, -0.050595545283399025, -0.01539801118980342, 0.07246534065736006, -0.0031378261578002054, 0.01902150153311637, -0.09209018846692514, 0.04309713696631712, -0.05093880722986939, -0.05619977383138075, 0.002020661600036244, 0.02901857510257151], [-0.044613920991676805, -0.0171511645128694, -0.05801708161136126, -0.03146578616378253, -0.04590339616973149, -0.01435543810370945, -0.08238695526089633, -0.01682237551625121, 0.046492209059695026, 0.04281975877286555, -0.08229249635350139, -0.03391708560379649, 0.06751994169146898, 0.03667716530803498, -0.0093070768963732, -0.00041997842212329053], [0.09364556242501938, 0.06628958466766861, 0.005729206893789019, 0.0648640280622772, 0.045000475510313415, -0.0588206026976696, 0.09866579935868283, -0.003663099132729575, 0.05985858540467673, -0.08380720383190919, 0.04779138107581796, -0.09216680490830285, 0.022630579053154132, -0.03854381081620115, -0.01335528003730746, 0.0327342497932897], [-0.022431726798188348, 0.007432975037316636, -0.09736095914642205, 0.0774493771045274, 0.018223026192246628, -0.042468691397523406, -0.007073673279811877, -0.01060693073250607, 0.0565470473733331, -0.05737797148100748, 0.07739335713592646, 0.018715266490230944, -0.09498448632944884, 0.09495328709267613, -0.045118674537911255, -0.09505680715906742], [0.07160237408732305, -0.07153628550691105, -0.023659204078740226, 0.04306606559130619, 0.09456515204798376, -0.08131273190313451, -0.03923365787654409, 0.04389303311749862, -0.005386262752671511, 0.05395825659009919, -0.08044044181170014, 0.015591485536805028, -0.05002518586971008, -0.09305529535082069, -0.09824362232302564, -0.016311024012092345], [-0.002869181592444403, -0.03543114678533452, 0.044000944942563326, -0.06803824531623041, 0.06341683807525711, -0.09789322132990284, -0.056081909706940006, -0.031460740817009336, 0.049619070740438254, 0.03380660669166922, 0.029744558272754153, -0.024911361099766195, 0.009006689465641182, 0.05988579203622366, 0.08089055421104399, 0.009829534975629151], [0.07187301515684262, -0.08612045142924524, -0.09864643627708608, 0.06038738214029096, 0.08961508952684656, -0.09973159833088703, 0.08976212867601492, 0.01324566648722747, 0.08815628541888261, -0.036959682477889326, -0.04712568032704734, -0.096716126086509, -0.0757950742063061, 0.0681944494329644, -0.03182498718922016, 0.0011692931265341988], [0.005287586374951858, 0.04696973846271855, -0.06749080943948138, -0.08675849994288472, 0.02242501077330015, 0.03722810760542392, 0.013666891694086282, 0.09669729522054418, 0.07941148350935752, 0.096235638978204, -0.026045630734004833, 0.02677461594884203, -0.06456169477482897, -0.01266464335889468, 0.02299785393241829, -0.05019984975393539], [0.06873474915141956, 0.03917288041377112, 0.01545688435915822, -0.06345989121852728, -0.03003599081872088, -0.007613152024347758, 0.06614738984569353, 0.0880150363444881, 0.08807609441949756, -0.08925240865994584, -0.012880434995701419, -0.016687578310493723, -0.04596276730913702, -0.03476570994903949, 0.09649710170324347, 0.0801608901129508], [0.006532982718006109, 0.08511036503083516, 0.029146046429278785, -0.07325378325588375, 0.017197899133371577, -0.04052012232125771, 0.07912764738924512, -0.09190061037379621, 0.09085642824962337, -0.0091215189506062, 0.05450868809517278, -0.012954303814652124, -0.004281914978175783, 0.09277734977028958, 0.028703808154357847, 0.061014263935147445], [-0.013934902242830716, -0.029658590679840804, -0.026513398491469345, -0.02220804162407668, 0.0017804733651407556, 0.0404624109440451, -0.09937395181395699, -0.027128791328314805, -0.013165627882386134, -0.04357743540567327, -0.011649802798956443, 0.0434568812591458, -0.04371812813477208, 0.0205444231295596, -0.09346117793452258, -0.0770583493003475], [0.06762569650979981, -0.08931958023471542, 0.04579976275945577, -0.012466071282426272, -0.050726895519059845, 0.0863251931883444, -0.05659770388480843, -0.037970159669117924, 0.054781257731319435, 0.09831979681391989, 0.08679457639026436, 0.022810191464268215, 0.04969950419081264, 0.02049184335159733, 0.006763870744612355, -0.07807760529333972], [0.09358230738278027, 0.039337741424145145, 0.09186942936098695, -0.051511359204248965, 0.014557616864743751, -0.057993956430308226, 0.08804583762691598, -0.09125978149876648, 0.06325037950613102, -0.06547959288581011, -0.07641980495103413, 0.007020055528099345, -0.019335151345452096, 0.0473643482224426, -0.09626996964623301, 0.09499897252682754], [-0.05982331853290486, 0.021228028202712947, -0.02246010996613004, -0.001716102106736117, -0.014035381658893821, 0.09550293698047241, 0.0958686850760778, -0.08407407600129638, -0.08122022517069792, 0.07884645686330674, 0.003631875950100727, 0.05208597689813741, 0.01564206928066103, -0.08793525168130159, -0.048857001769693965, 0.024699881831478355], [-0.09965754695582052, -0.07972846782307219, -0.0018063092916257518, -0.08591068005786857, 0.05547596668990134, -0.07349381180655838, 0.010732167484979405, -0.028109964148992583, -0.054733004147163734, 0.0732925671803244, -0.09248313306119496, 0.0529814755473893, 0.07793274529965444, 0.014908373289931377, -0.060181014345255114, -0.01615768267163318], [0.005211825815790894, 0.042881295338355656, -0.07760542271336222, 0.06274339211879708, 0.04579883953103223, -0.07444626200269232, -0.007569865884109839, 0.026619969237990482, 0.024726617331096892, 0.02214398618814628, 0.009154978255877123, 0.07265600827883201, -0.014398345232034648, 0.009809828466351922, -0.03759978327651636, -0.06423493573036805]]\n",
            "[[-0.01920293378170275, -0.09645576065069482, -0.04769883408281764, 0.07173831594480891, 0.07835178728023967, -0.07797020971418343, -0.019267559160721315, 0.03909099912630065, -0.0014209189909119458, 0.08561083555668994, -0.09052061521673849, -0.031425777732305704, 0.09812316596572179, 0.0019157519136233426, -0.05084248599972916, 0.07308036751891214], [-0.04770004243438766, 0.07854981751873812, -0.011183952395552166, -0.09629602039937615, 0.039923844549899105, 0.08440780060775706, 0.02579324376807526, -0.022557078585629275, -0.0358367662490239, 0.020851495708155057, -0.036758289665220566, -0.06782687706725062, -0.09346302517083097, 0.03177906188991395, 0.02942753166839418, -0.035493598714027574], [-0.09218203289209037, -0.09378340471052451, -0.04170792748678323, 0.07733295901328668, 0.012320147762599954, 0.05594361252784308, -0.03211161627303543, -0.07062973941266303, -0.001669878599076191, -0.005534527372508902, -0.027198966930519708, -0.08331424371486076, 0.08322424627286298, 0.03185760973305547, -0.029145014039230158, -0.07467946773121596], [0.018999818475511757, -0.09776784213684409, -0.07500144928492276, -0.04264712670363829, -0.06775535438971125, -0.09250251156181176, -0.09884593318581412, -0.010082104909782187, 0.08674827862854809, -0.0023392636588839056, 0.01296050777111728, 0.054844615425742704, 0.05759703963527612, 0.031215178787388866, -0.04574425311125155, -0.07550840509099087], [0.03015385879908701, 0.07911627535053159, -0.09494061438213236, -0.0029415459588919782, 0.037957650164362366, 0.08719344796921324, -0.058618839916048576, -0.027461896826070142, 0.034253343088300574, 0.021373179207014804, 0.063561564977671, 0.07819641058241429, -0.053223444438372305, 0.08641311954682199, -0.06213874307782814, -0.04305949967725758], [-0.058011918649259475, 0.011763067942799844, -0.0856426723053154, 0.024584496389880053, 0.06445470830644784, 0.09034043409848216, -0.09635406262788467, -0.05564178733739749, 0.011641564140340545, 0.024151901324645998, -0.042855539597250795, 0.02771432759583785, 0.05482263892123099, 0.035082459852162344, 0.009978400457747628, -0.07869732846785932], [0.05467409604821654, -0.08551686496612038, -0.011442366902317147, 0.021106712486693626, 0.03192180543486676, 0.04394583423614691, -0.02559651129024263, -0.030928782010425728, -0.0583642918063934, -0.06942126134697546, 0.059832007688973676, 0.08386517433795589, 0.06535962312876785, 0.06903331559483615, 0.08915409872444607, 0.06409572383078706], [0.08042267788146291, -0.075109834267623, 0.01558865329262722, 0.02027853761008558, 0.061062791307864676, 0.012198756100302233, 0.01720480615046178, 0.06196025183655656, -0.09998238817748202, 0.09034242544235345, 0.07230490082499329, -0.001291801710276297, 0.030769000365213663, -0.0291896022447254, -0.02690589063953617, 0.008061545728534436]]\n",
            "input [4, 19, 5, 12, 0, 3]\n",
            "Logits örneği: [-0.00015771155297768808, -5.9893622408805875e-05, 0.00011482872319577641, 0.00025315829741673546, -0.0008876565123079916] ...\n",
            "Üretilen token dizisi: [9, 14, 17, 19, 11, 12, 8, 4, 19, 19, 6, 7]\n"
          ]
        }
      ]
    }
  ]
}